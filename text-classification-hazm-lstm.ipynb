{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-insurance",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-02T10:16:38.579438Z",
     "iopub.status.busy": "2021-05-02T10:16:38.574473Z",
     "iopub.status.idle": "2021-05-02T10:17:12.059169Z",
     "shell.execute_reply": "2021-05-02T10:17:12.058416Z"
    },
    "papermill": {
     "duration": 33.50469,
     "end_time": "2021-05-02T10:17:12.059394",
     "exception": false,
     "start_time": "2021-05-02T10:16:38.554704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\r\n",
      "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 243 kB 420 kB/s \r\n",
      "\u001b[?25hCollecting et-xmlfile\r\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\r\n",
      "Installing collected packages: et-xmlfile, openpyxl\r\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.7\r\n",
      "Collecting hazm\r\n",
      "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 316 kB 412 kB/s \r\n",
      "\u001b[?25hCollecting libwapiti>=0.2.1\r\n",
      "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 233 kB 3.7 MB/s \r\n",
      "\u001b[?25hCollecting nltk==3.3\r\n",
      "  Downloading nltk-3.3.0.zip (1.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 5.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk==3.3->hazm) (1.15.0)\r\n",
      "Building wheels for collected packages: nltk, libwapiti\r\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394470 sha256=cfbe7d5ae6458ec8b8e4a831a5faa3c37e6494c7554de48f74e750c872d8bdf6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\r\n",
      "  Building wheel for libwapiti (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=169454 sha256=b63d704b3344613c4122b93311fc6d5e9abb25188467ad56b44788b55e7b59e0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\r\n",
      "Successfully built nltk libwapiti\r\n",
      "Installing collected packages: nltk, libwapiti, hazm\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.2.4\r\n",
      "    Uninstalling nltk-3.2.4:\r\n",
      "      Successfully uninstalled nltk-3.2.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.3 which is incompatible.\u001b[0m\r\n",
      "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "descending-foster",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:17:12.129662Z",
     "iopub.status.busy": "2021-05-02T10:17:12.128911Z",
     "iopub.status.idle": "2021-05-02T10:17:13.770937Z",
     "shell.execute_reply": "2021-05-02T10:17:13.771488Z"
    },
    "papermill": {
     "duration": 1.680733,
     "end_time": "2021-05-02T10:17:13.771720",
     "exception": false,
     "start_time": "2021-05-02T10:17:12.090987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/persian-digikala-reviwes/2-p9vcb5bb.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from hazm import *\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "communist-pierre",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:17:13.838713Z",
     "iopub.status.busy": "2021-05-02T10:17:13.837868Z",
     "iopub.status.idle": "2021-05-02T10:17:47.678432Z",
     "shell.execute_reply": "2021-05-02T10:17:47.678974Z"
    },
    "papermill": {
     "duration": 33.877368,
     "end_time": "2021-05-02T10:17:47.679197",
     "exception": false,
     "start_time": "2021-05-02T10:17:13.801829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../input/persian-digikala-reviwes/2-p9vcb5bb.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "express-perth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:17:47.745091Z",
     "iopub.status.busy": "2021-05-02T10:17:47.744017Z",
     "iopub.status.idle": "2021-05-02T10:17:54.308876Z",
     "shell.execute_reply": "2021-05-02T10:17:54.308286Z"
    },
    "papermill": {
     "duration": 6.599271,
     "end_time": "2021-05-02T10:17:54.309036",
     "exception": false,
     "start_time": "2021-05-02T10:17:47.709765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7596, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "df = df.dropna()\n",
    "\n",
    "df['comment'] = df['comment'].apply(lambda x:normalizer.normalize(x))\n",
    "df = df[['comment','likes','dislikes','recommend']]\n",
    "\n",
    "df['comment'] = df['comment'].apply(lambda x: re.sub('[0-9]+', ' ', x))\n",
    "\n",
    "df = df[((df['likes']/df['dislikes'])>1)&(df['recommend'] == \"recommended\")\n",
    "       |((df['recommend'] == \"not_recommended\")&(df['dislikes']/df['likes']>1))]\n",
    "\n",
    "To_Process = df[['recommend','comment']]\n",
    "To_Process.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elementary-hollow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:17:54.380876Z",
     "iopub.status.busy": "2021-05-02T10:17:54.376953Z",
     "iopub.status.idle": "2021-05-02T10:17:54.386593Z",
     "shell.execute_reply": "2021-05-02T10:17:54.386026Z"
    },
    "papermill": {
     "duration": 0.045716,
     "end_time": "2021-05-02T10:17:54.386760",
     "exception": false,
     "start_time": "2021-05-02T10:17:54.341044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(To_Process, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-frost",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:17:54.460166Z",
     "iopub.status.busy": "2021-05-02T10:17:54.458983Z",
     "iopub.status.idle": "2021-05-02T10:18:02.170681Z",
     "shell.execute_reply": "2021-05-02T10:18:02.169990Z"
    },
    "papermill": {
     "duration": 7.751058,
     "end_time": "2021-05-02T10:18:02.170841",
     "exception": false,
     "start_time": "2021-05-02T10:17:54.419783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19086 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the sequence lengths, max number of words and embedding dimensions\n",
    "MAX_SEQUENCE_LENGTH = 300 #can plot a graph for length\n",
    "MAX_NB_WORDS = 15000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Get the frequently occurring words\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train.comment)\n",
    "train_sequences = tokenizer.texts_to_sequences(train.comment)\n",
    "test_sequences = tokenizer.texts_to_sequences(test.comment)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "#some padding shit\n",
    "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becoming-cleaners",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:18:02.250100Z",
     "iopub.status.busy": "2021-05-02T10:18:02.249133Z",
     "iopub.status.idle": "2021-05-02T10:18:02.253131Z",
     "shell.execute_reply": "2021-05-02T10:18:02.252601Z"
    },
    "papermill": {
     "duration": 0.050068,
     "end_time": "2021-05-02T10:18:02.253300",
     "exception": false,
     "start_time": "2021-05-02T10:18:02.203232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_recommended' 'recommended']\n"
     ]
    }
   ],
   "source": [
    "#some shit with labels\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_labels = train['recommend']\n",
    "test_labels = test['recommend']\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-patient",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:18:02.325630Z",
     "iopub.status.busy": "2021-05-02T10:18:02.324762Z",
     "iopub.status.idle": "2021-05-02T10:18:02.328696Z",
     "shell.execute_reply": "2021-05-02T10:18:02.328138Z"
    },
    "papermill": {
     "duration": 0.042899,
     "end_time": "2021-05-02T10:18:02.328859",
     "exception": false,
     "start_time": "2021-05-02T10:18:02.285960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#change data types (actualy idk why)\n",
    "labels_train = to_categorical(np.asarray(train_labels))\n",
    "labels_test = to_categorical(np.asarray(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "measured-marshall",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:18:02.406011Z",
     "iopub.status.busy": "2021-05-02T10:18:02.405291Z",
     "iopub.status.idle": "2021-05-02T10:18:02.815491Z",
     "shell.execute_reply": "2021-05-02T10:18:02.814469Z"
    },
    "papermill": {
     "duration": 0.454283,
     "end_time": "2021-05-02T10:18:02.815710",
     "exception": false,
     "start_time": "2021-05-02T10:18:02.361427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Sequential' from 'keras.layers' (/opt/conda/lib/python3.7/site-packages/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-56e141cc1a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Embedding: batch_size*input_length --> batch_dimension(none)*input_length*output_dim(embbeding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Sequential' from 'keras.layers' (/opt/conda/lib/python3.7/site-packages/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Sequential, Model, Dense, Input, LSTM, Embedding, Dropout, Activation, BatchNormalization, Flatten\n",
    "model2 = Sequential()\n",
    "\n",
    "#Embedding: batch_size*input_length --> batch_dimension(none)*input_length*output_dim(embbeding_dim)\n",
    "model2.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model2.add(LSTM(units=16, activation='relu', recurrent_activation='hard_sigmoid',return_sequences=True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model2.compile(loss = 'binary_crossentropy',optimizer='adam',metrics = ['accuracy'])\n",
    "model2.fit(train_data, labels_train, batch_size=16, epochs=5, validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrative-penetration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:18:02.897115Z",
     "iopub.status.busy": "2021-05-02T10:18:02.891672Z",
     "iopub.status.idle": "2021-05-02T10:18:02.927824Z",
     "shell.execute_reply": "2021-05-02T10:18:02.927228Z"
    },
    "papermill": {
     "duration": 0.077725,
     "end_time": "2021-05-02T10:18:02.928014",
     "exception": false,
     "start_time": "2021-05-02T10:18:02.850289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b724681b69d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted=model2.predict(test_data)\n",
    "predicted\n",
    "\n",
    "precision, recall, fscore, support = score(labels_test, predicted.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(labels_test, predicted.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alpha-reality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-02T10:18:03.029363Z",
     "iopub.status.busy": "2021-05-02T10:18:03.023860Z",
     "iopub.status.idle": "2021-05-02T10:18:03.041028Z",
     "shell.execute_reply": "2021-05-02T10:18:03.041546Z"
    },
    "papermill": {
     "duration": 0.080151,
     "end_time": "2021-05-02T10:18:03.041764",
     "exception": false,
     "start_time": "2021-05-02T10:18:02.961613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend                                          recommended\n",
      "comment      من واقعا ازش راضیم ولی تنها مشکلم گردنشه که هم...\n",
      "Name: 48821, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b59aaf138c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "#example\n",
    "k = 3\n",
    "print(test.iloc[k])\n",
    "x = model2(test_data[k:k+1,:])\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 97.131001,
   "end_time": "2021-05-02T10:18:05.387876",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-02T10:16:28.256875",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
